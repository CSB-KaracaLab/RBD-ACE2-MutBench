{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating SARS-CoV-2 RBD ACE2 Benchmarking Dataset\n",
    "\n",
    "In this study we benchmarked RBD and ACE2 point mutations by using structure based ∆∆G predictors on deep mutagenesis dataset. \n",
    "\n",
    "These predictors are \n",
    "- HADDOCK, \n",
    "- FoldX, \n",
    "- EvoEF1, \n",
    "- MutaBind2, and\n",
    "- SSIPe.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining root and data directory path \n",
    "rootdir = pathlib.Path('.').resolve(strict=True)\n",
    "datadir = rootdir.parents [1] / 'Output_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental datasets\n",
    "\n",
    "ACE2 and RBD proteins scanned with point mutations by using deep mutagenesis technique. And binding and expression values corresponding to the mutation were released. We selected only interface mutations from the result of this experiment. So our experimental dataset contains totally 263 cases - 179 ACE2 and 84 RBD cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "ACE2 = pd.read_csv(datadir / 'ACE2_Experimental_dataset.csv', delimiter=',')\n",
    "ACE2.columns=['#case_id','exp_binding']\n",
    "#create protein column to represent which case belong which protein \n",
    "ACE2['protein'] = \"ACE2\"\n",
    "\n",
    "RBD = pd.read_csv(datadir / 'RBD_Experimental_dataset.csv', delimiter=',')\n",
    "RBD = RBD[['#case_id', 'RBD_bind_avg']]\n",
    "RBD.columns=['#case_id','exp_binding']\n",
    "RBD['protein'] = \"RBD\"\n",
    "\n",
    "# concatanate ACE2 and RBD dataset to build experimental dataset of our study\n",
    "Experimental_dataset = pd.concat([ACE2,RBD])\n",
    "# setting case id as an index is necessary for joining datasets in an accurate order to the next level\n",
    "Experimental_dataset=Experimental_dataset.set_index('#case_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ∆∆G calculation of predictors\n",
    "\n",
    "In our case ∆∆G represents the energy differences of the protein complex of ACE2-RBD upon a point mutation. Therefore, we assume that predicted ∆∆G must be correlated with the experimental binding energy. Since HADDOCK, FoldX and EvoEF1 do not output a ∆∆G for a mutation, we calculated the ∆∆G by subtracting ∆G of wild type from ∆G of mutant. MutaBind2 and SSIPe directly output a ∆∆G in their result pages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HADDOCK\n",
    "\n",
    "We used following formula to calculate ∆∆G HADDOCK scores:\n",
    "- ∆∆G = [Mutant HADDOCK score] - [Wild type HADDOCK score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import HADDOCK score dataset\n",
    "HADDOCK_score = pd.read_csv(datadir / 'HADDOCK_scores.csv', delimiter=',')\n",
    "\n",
    "# define wild type HADDOCK score\n",
    "wt = HADDOCK_score[HADDOCK_score['#case_id']==\"WT\"]\n",
    "wt_score = wt['haddock-score'].values.tolist()\n",
    "\n",
    "# to remove wild type row from dataset; first define case id column as an index, then drop the row via index. \n",
    "# further, reset indexing and organize column order.\n",
    "HADDOCK_score = HADDOCK_score.set_index(\"#case_id\")\n",
    "HADDOCK_score = HADDOCK_score.drop(labels=['WT'], axis=0)\n",
    "HADDOCK_score = HADDOCK_score.reset_index()\n",
    "HADDOCK_score = HADDOCK_score[['#case_id', 'haddock-score']]\n",
    "\n",
    "# calculate ∆∆G\n",
    "HADDOCK_score['haddock-ddg'] = HADDOCK_score['haddock-score'] - wt_score\n",
    "\n",
    "# remove the haddock-score column\n",
    "HADDOCK_scores = HADDOCK_score.drop(labels=['haddock-score'], axis=1)\n",
    "HADDOCK_scores=HADDOCK_scores.set_index('#case_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FoldX\n",
    "\n",
    "FoldX produces wild type score for each mutation. Therefore, we used each wild type score of corresponding mutation to calculate ∆∆G. We used following formula to calculate ∆∆G FoldX scores:\n",
    "\n",
    "- ∆∆G = [Mutant FoldX score] - [Wild type FoldX score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import FoldX score dataset\n",
    "FoldX_score = pd.read_csv(datadir / 'FoldX_scores.csv', delimiter=',')\n",
    "\n",
    "# calculate ∆∆G\n",
    "FoldX_score['foldx-ddg'] = FoldX_score['foldx-score-mut'] - FoldX_score['foldx-score-wt']\n",
    "\n",
    "# remove foldx-score-mut and foldx-score-wt column\n",
    "FoldX_scores = FoldX_score.drop(labels=['foldx-score-mut', 'foldx-score-wt'], axis=1)\n",
    "FoldX_scores=FoldX_scores.set_index('#case_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FoldXwater\n",
    "\n",
    "FoldX serves as an option to contribute to crystallographic water bridges. We builded our mutations by using the Crystalwater option since the FoldX team suggested using this option in the last COVID19 related [paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1008450). The ∆∆G calculation is the exactly same with the FoldX.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import FoldXwater score dataset\n",
    "FoldXwater_score = pd.read_csv(datadir / 'FoldXwater_scores.csv', delimiter=',')\n",
    "\n",
    "# calculate ddg\n",
    "FoldXwater_score['foldxwater-ddg'] = FoldXwater_score['foldx-score-mut'] - FoldXwater_score['foldx-score-wt']\n",
    "\n",
    "# remove foldx-score-mut and foldx-score-wt column\n",
    "FoldXwater_scores = FoldXwater_score.drop(labels=['foldx-score-mut', 'foldx-score-wt'], axis=1)\n",
    "FoldXwater_scores=FoldXwater_scores.set_index('#case_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EvoEF1 \n",
    "\n",
    "For the ∆∆G calculation of EvoEF1 we followed exactly the same formula. \n",
    "- ∆∆G = [Mutant EvoEF1 score] - [Wild type EvoEF1 score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import EvoEF1 score dataset\n",
    "EvoEF1_score = pd.read_csv(datadir / 'EvoEF1_scores.csv', delimiter=',')\n",
    "\n",
    "# define WT EvoEF1 score\n",
    "wt= EvoEF1_score[EvoEF1_score['#case_id'].str.contains(\"WT\")]\n",
    "wt_score = wt['evoef1-score'].values.tolist()\n",
    "\n",
    "# to remove WT row from dataset; first define mutation_type column as index, then drop the row via index. \n",
    "# further, reset indexing and organize column order.\n",
    "EvoEF1_score = EvoEF1_score.set_index(\"#case_id\")\n",
    "EvoEF1_score = EvoEF1_score.drop(labels=['WT'], axis=0)\n",
    "EvoEF1_score = EvoEF1_score.reset_index()\n",
    "EvoEF1_score = EvoEF1_score[['#case_id', 'evoef1-score']]\n",
    "\n",
    "# calculate ddg\n",
    "EvoEF1_score['evoef1-ddg'] = EvoEF1_score['evoef1-score'] - wt_score\n",
    "\n",
    "# remove evoef1-score column\n",
    "EvoEF1_scores = EvoEF1_score.drop(labels=['evoef1-score'], axis=1)\n",
    "EvoEF1_scores=EvoEF1_scores.set_index('#case_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MutaBind2,  SSIPe and UEP\n",
    "\n",
    "There is no need to calculate ∆∆G since MutaBind2, SSIPe, and UEP output directly to ∆∆G score. Basically we selected ∆∆G column from the result pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import  MutaBind2 ∆∆G score dataset\n",
    "MutaBind2_scores = pd.read_csv(datadir / 'MutaBind2_scores.csv', delimiter=',')\n",
    "# select case id and ∆∆G columns, rename the columns\n",
    "MutaBind2_scores = MutaBind2_scores[['Mutation','DDG']]\n",
    "MutaBind2_scores.rename(columns = {'Mutation': '#case_id', 'DDG': 'mutabind2-ddg'}, inplace = True)\n",
    "MutaBind2_scores=MutaBind2_scores.set_index('#case_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import  SSIPe ∆∆G score dataset\n",
    "SSIPe_scores = pd.read_csv(datadir / 'SSIPe_result.txt', delimiter=' ')\n",
    "# select case id and ∆∆G columns, rename the columns\n",
    "SSIPe_scores = SSIPe_scores[['mutations','DDG']]\n",
    "SSIPe_scores.rename(columns = {'mutations': '#case_id','DDG': 'ssipe-ddg'}, inplace = True)\n",
    "\n",
    "#change the case id format FE490K -> F490K -remove chain name, E\n",
    "case_id = SSIPe_scores['#case_id']\n",
    "\n",
    "#remove ; sign\n",
    "case_id_list = []\n",
    "for i in case_id:\n",
    "    caseid = i[:-1]\n",
    "    case_id_list.append(caseid)\n",
    "\n",
    "case_id_column = []\n",
    "for i in case_id_list:\n",
    "    caseid = i[0] + i[2:]\n",
    "    case_id_column.append(caseid)\n",
    "    \n",
    "case_id_column = pd.DataFrame(case_id_column, columns=['#case_id'])\n",
    "ddg_column = SSIPe_scores[['ssipe-ddg']]\n",
    "# concatanate case id and ddg columns\n",
    "SSIPe_scores = pd.concat([case_id_column,ddg_column], axis=1)\n",
    "SSIPe_scores = SSIPe_scores.set_index('#case_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import UEP ∆∆G score dataset\n",
    "UEP_scores = pd.read_csv(datadir / '6m0j_input_UEP_A_E.csv', delimiter=',')\n",
    "\n",
    "# UEP result page is as a 2 dimentional array, we converged the file to 1 dimentional array by using following steps \n",
    "\n",
    "\n",
    "# we used single letter amino acid abbreviation, so we converted 3 letter abbreviation to single\n",
    "abbreviation = dict(ALA='A', ARG='R', ASN='N', ASP='D', CYS='C', GLN='Q', GLU='E', GLY='G', HIS='H', ILE='I',\n",
    "                LEU='L', LYS='K', MET='M', PHE='F', PRO='P', SER='S', THR='T', TRP='W', TYR='Y', VAL='V') \n",
    "aa_columns=UEP_scores.columns.tolist()\n",
    "x = aa_columns[1:]\n",
    "single_letter_aa = []\n",
    "for i in x:\n",
    "    aa=abbreviation[i]\n",
    "    single_letter_aa.append(aa)\n",
    "    \n",
    "# array format for extract case list, cases represented as [wild-type residue][position][mutant residue], A111C\n",
    "UEP_array = pd.DataFrame.to_numpy(UEP_scores)\n",
    "caselist = []\n",
    "for case in UEP_array:\n",
    "    pos_wt = case[0][2:]\n",
    "    wt = pos_wt[-3:]\n",
    "    wt=abbreviation[wt]\n",
    "    position = pos_wt[:-4]\n",
    "    wt_position = [wt+position]\n",
    "    for i in wt_position:\n",
    "        for e in single_letter_aa:\n",
    "            caselist.append(f'{i}{e}')  \n",
    "\n",
    "# list format for extract ∆∆G scores\n",
    "UEP_list = UEP_scores.values.tolist()             \n",
    "ddg_values = []\n",
    "for i in UEP_list:\n",
    "    a=i[1:]\n",
    "    ddg_values.append(a)\n",
    "list_ddg = []\n",
    "for a in range(28):\n",
    "    for i in ddg_values[a]:\n",
    "        list_ddg.append(i)\n",
    "\n",
    "# append case id and ∆∆G score columns        \n",
    "data=[]\n",
    "for i,k in zip(caselist, list_ddg):\n",
    "            data.append([i,k])\n",
    "UEP_score = pd.DataFrame(data, columns=['#case_id', 'uep-ddg'])\n",
    "# NaN cases must be romoved from the dataset\n",
    "UEP_scores=UEP_score.dropna()\n",
    "UEP_scores = UEP_scores.set_index('#case_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Predictors' ∆∆G Together\n",
    "\n",
    "We will have 2 dataset for further analysis, one of them main dataset consists of 263 cases. The other one UEP dataset consists of 129 cases, contains only the common cases between main dataset and UEP output. Consider that UEP suggests a ∆∆G energy of a mutation if it is highly-packed residue with has at least 2 non-covalent bond. Therefore, we missed nearly half of our cases while constructing UEP dataset. \n",
    "\n",
    "- Predictors' performance on main dataset presents the performance on interface mutations.\n",
    "- Predictors' performance on UEP dataset presents the performances on highly-packed interface mutations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main dataset\n",
    "predictors = [Experimental_dataset, HADDOCK_scores, FoldX_scores, FoldXwater_scores, EvoEF1_scores, MutaBind2_scores, SSIPe_scores]\n",
    "SARS_CoV_2_RBD_ACE2_benchmarking_dataset = pd.concat(predictors, axis=1,join=\"inner\")\n",
    "\n",
    "# reset the index\n",
    "SARS_CoV_2_RBD_ACE2_benchmarking_dataset=SARS_CoV_2_RBD_ACE2_benchmarking_dataset.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UEP dataset\n",
    "predictors = [Experimental_dataset, HADDOCK_scores, FoldX_scores, FoldXwater_scores, EvoEF1_scores, MutaBind2_scores, SSIPe_scores, UEP_scores]\n",
    "UEP_SARS_CoV_2_RBD_ACE2_benchmarking_dataset = pd.concat(predictors, axis=1,join=\"inner\")\n",
    "\n",
    "# reset the index\n",
    "UEP_SARS_CoV_2_RBD_ACE2_benchmarking_dataset=UEP_SARS_CoV_2_RBD_ACE2_benchmarking_dataset.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction status and Metric Analysis\n",
    "\n",
    "In the scope of the study we presented performances of predictor and dissected this performances by using metrics. These amino acid change related metrics are:\n",
    "\n",
    "- Volume change,\n",
    "- Hydrophobicity change,\n",
    "- Flexibility change, and\n",
    "- Physicochemical property change.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction status\n",
    "\n",
    "Experimental energy where bigger than zero represents binding enhancing mutations, and less than zero represents binding decreasing mutations. According to that we classified mutations as enriched and depleted, respectively. On the other hand if predicted binding score of predictors are less than zero, it represents favorable binding means that enhancing binding. We used this description to determined the prediction status of predictors (success of failure) for a certain mutation by comparing predicted score to experimental binding energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "def prediction_status(df):\n",
    "    columns=df.columns\n",
    "    ddg_columns=columns[columns.str.contains('ddg')]\n",
    "\n",
    "    for i in ddg_columns:\n",
    "        enriched = df[df['exp_binding']>0]\n",
    "        depleted = df[df['exp_binding']<0]\n",
    "\n",
    "        condition_enr = [\n",
    "                (enriched.loc[:, [f'{i}']] < 0),\n",
    "                (enriched.loc[:, [f'{i}']] >= 0)]\n",
    "\n",
    "        value_enr = ['success', 'failure']\n",
    "        enriched.loc[:,[f'{i}-prediction']] = np.select(condition_enr, value_enr)\n",
    "\n",
    "        condition_dep = [\n",
    "                (depleted.loc[:, [f'{i}']] <= 0),\n",
    "                (depleted.loc[:, [f'{i}']] > 0)]\n",
    "\n",
    "        value_dep = ['failure', 'success']\n",
    "        depleted.loc[:,[f'{i}-prediction']] = np.select(condition_dep, value_dep)\n",
    "        df=pd.concat([enriched, depleted])\n",
    "    return (df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume Change \n",
    "\n",
    "This function concatenates vdW volume change of mutations as a column to corresponding dataset. \n",
    "Note that there should be '#case_id' column: [wild-type residue][position][mutated residue], A111C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def volume_change(df):\n",
    "    volume = dict(A=0.05702, R=0.58946, N=0.22972, D=0.21051, C=0.14907, Q=0.34861, E=0.32837, G=0.00279, H=0.37694, I=0.37671,\n",
    "              L=0.37876, K=0.45363, M=0.38872, F=0.55298, P=0.2279, S=0.09204, T=0.19341, W=0.79351, Y=0.6115, V=0.25674)\n",
    "    \n",
    "    list_caseid = df[['#case_id']].values.tolist()\n",
    "\n",
    "    volume_change = []\n",
    "    for i in list_caseid:\n",
    "        mutant_resi= i[0][-1]\n",
    "        wt_resi= i[0][0]\n",
    "        #volume dictionary contains vdW volume of amino acids\n",
    "        vdW_mutant_resi =volume[mutant_resi]\n",
    "        vdW_wt_resi=volume[wt_resi]\n",
    "        #2 place after the decimal\n",
    "        delta_vdW=round(vdW_mutant_resi-vdW_wt_resi,2)\n",
    "        volume_change.append(delta_vdW)\n",
    "\n",
    "    volume_change_column=pd.DataFrame(volume_change, columns=['volume_change'])\n",
    "    df = pd.concat([df,volume_change_column], axis=1)\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hydrophobicity change\n",
    "\n",
    "This function concatenates hydrophobicity change of mutations as a column to corresponding dataset. Note that there should be '#case_id' column: [WT residue][position][mutated residue], A111C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hydrophobicity_change(df):\n",
    "    hydrophobicity = dict(A=0.62, R=-2.53, N=-0.78, D=-0.90, C=0.29, Q=-0.85, E=-0.74, G=0.48, H=-0.40, I=1.38,\n",
    "                L=1.06, K=-1.50, M=0.64, F=1.19, P=0.12, S=-0.18, T=-0.05, W=0.81, Y=0.26, V=1.08) \n",
    "\n",
    "    list_caseid = df[['#case_id']].values.tolist()\n",
    "\n",
    "    hydrophobicity_change = []\n",
    "    for i in list_caseid:\n",
    "        mutant_resi= i[0][-1]\n",
    "        wt_resi= i[0][0]\n",
    "        #hydrophobicity dictionary contains hydrophobicity value of amino acids\n",
    "        hyd_mutant_resi =hydrophobicity[mutant_resi]\n",
    "        hyd_wt_resi=hydrophobicity[wt_resi]\n",
    "        #2 place after the decimal\n",
    "        delta_hyd=round(hyd_mutant_resi-hyd_wt_resi,2)\n",
    "        hydrophobicity_change.append(delta_hyd)\n",
    "   \n",
    "    hydrophobicity_change_column=pd.DataFrame(hydrophobicity_change, columns=['hydrophobicity_change'])\n",
    "    df = pd.concat([df,hydrophobicity_change_column], axis=1)\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flexibility Change\n",
    "\n",
    "This function concatenates flexibility change of mutations as a column to corresponding dataset. Note that there should be '#case_id' column: [WT residue][position][mutated residue], A111C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flexibility_change(df):\n",
    "    flexibility = dict(A=1, R=81, N=3, D=3, C=3, Q=9, E=9, G=1, H=3, I=9,\n",
    "                L=9, K=81, M=27, F=3, P=2, S=3, T=3, W=3, Y=3, V=3) \n",
    "\n",
    "    list_caseid = df[['#case_id']].values.tolist()\n",
    "\n",
    "    flexibility_change = []\n",
    "    for i in list_caseid:\n",
    "        mutant_resi= i[0][-1]\n",
    "        wt_resi= i[0][0]\n",
    "        #flexibility dictionary contains hydrophobicity value of amino acids\n",
    "        flex_mutant_resi =flexibility[mutant_resi]\n",
    "        flex_wt_resi=flexibility[wt_resi]\n",
    "        #2 place after the decimal\n",
    "        delta_flex=round(flex_mutant_resi-flex_wt_resi,2)\n",
    "        flexibility_change.append(delta_flex)\n",
    "   \n",
    "    flexibility_change_column=pd.DataFrame(flexibility_change, columns=['flexibility_change'])\n",
    "    df = pd.concat([df,flexibility_change_column], axis=1)\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physicochemical Property Change\n",
    "\n",
    "For this metric, first we classified amino acids as \n",
    "- non-polar, \n",
    "- polar, and \n",
    "- charge.\n",
    "\n",
    "Then we defined the changing between this classes as\n",
    "\n",
    "- no change,\n",
    "- polarity gain,\n",
    "- polarity loss,\n",
    "- chage gain, and\n",
    "- charge loss.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def physicochemical_property_change(df):\n",
    "    physicochemical_property = dict(A='non-polar', R='charge', N='polar', D='charge', C='non-polar', Q='polar',\n",
    "                                    E='charge', G='non-polar', H='charge', I='non-polar', L='non-polar', K='charge',\n",
    "                                    M='non-polar', F='non-polar', P='non-polar', S='polar', T='polar', W='non-polar',\n",
    "                                    Y='polar', V='non-polar') \n",
    "\n",
    "    list_caseid = df[['#case_id']].values.tolist()\n",
    "\n",
    "    wt = []\n",
    "    mutant = []\n",
    "    for i in list_caseid:\n",
    "        mutant_resi= i[0][-1]\n",
    "        wt_resi= i[0][0]\n",
    "        #physicochemical_property dictionary contains physicochemical property of amino acids\n",
    "        mutant_property =physicochemical_property[mutant_resi]\n",
    "        wt_property=physicochemical_property[wt_resi] \n",
    "\n",
    "        mutant.append(mutant_property)\n",
    "        wt.append(wt_property)\n",
    "\n",
    "    mutant_dataframe=pd.DataFrame(mutant, columns=['mutant_property'])\n",
    "    wt_dataframe=pd.DataFrame(wt, columns=['wt_property'])\n",
    "\n",
    "    df = pd.concat([df, wt_dataframe, mutant_dataframe], axis=1)\n",
    "    \n",
    "    properties=['non-polar', 'polar', 'charge']\n",
    "    for i in properties:\n",
    "        condition = [\n",
    "                (df.loc[:, ['mutant_property']] == 'non-polar'),\n",
    "                (df.loc[:, ['mutant_property']] == 'polar'),\n",
    "                (df.loc[:, ['mutant_property']] == 'charge')]\n",
    "        if i == 'non-polar':\n",
    "            value = ['no_change', 'polarity_gain', 'charge_gain']\n",
    "        elif i == 'polar':\n",
    "            value = ['no_change', 'polarity_loss', 'charge_gain']\n",
    "        elif i == 'charge':\n",
    "            value = ['charge_loss', 'charge_loss', 'no_change']\n",
    "\n",
    "\n",
    "        df.loc[:,['physicochem_property_change']] = np.select(condition, value)\n",
    "        df.drop(['mutant_property', 'wt_property'], inplace=True, axis=1)\n",
    "        return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Main and UEP Datasets by Using Defined Functions\n",
    "\n",
    "The datasets contain the following columns:\n",
    "- case id\n",
    "- experimental binding score\n",
    "- protein name\n",
    "- ∆∆G's of predictors\n",
    "- ∆∆G prediction status of predictors\n",
    "- Volume change\n",
    "- Hydrophobicity change\n",
    "- Flexibility change\n",
    "- Physicochemical property change of the mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARS_CoV_2_RBD_ACE2_benchmarking_dataset = physicochemical_property_change(flexibility_change(hydrophobicity_change(volume_change(prediction_status(SARS_CoV_2_RBD_ACE2_benchmarking_dataset)))))\n",
    "SARS_CoV_2_RBD_ACE2_benchmarking_dataset.to_csv(datadir / 'SARS-CoV-2-RBD_ACE2_benchmarking_dataset.csv', index=True, float_format='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "UEP_SARS_CoV_2_RBD_ACE2_benchmarking_dataset = physicochemical_property_change(flexibility_change(hydrophobicity_change(volume_change(prediction_status(UEP_SARS_CoV_2_RBD_ACE2_benchmarking_dataset)))))\n",
    "UEP_SARS_CoV_2_RBD_ACE2_benchmarking_dataset.to_csv(datadir / 'UEP_SARS-CoV-2-RBD_ACE2_benchmarking_dataset.csv', index=True, float_format='%.2f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
